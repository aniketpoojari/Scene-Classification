{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D82aEA-rHVDP"
   },
   "source": [
    "# IMPORTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 1740,
     "status": "ok",
     "timestamp": 1619026592869,
     "user": {
      "displayName": "aniket poojari",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Ggq_cw5GlJ_HceHGjFtLxCCLPqiYvg5ffKS76adUw=s64",
      "userId": "09624879631889696305"
     },
     "user_tz": -330
    },
    "id": "dtA0xzFx5gFc"
   },
   "outputs": [],
   "source": [
    "import numpy as np  \n",
    "import pandas as pd \n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "import torch \n",
    "import torch.nn as nn\n",
    "from torch.optim import Adam\n",
    "from torch.nn import Linear, ReLU, BCELoss, Sequential, Softmax\n",
    "from torchvision.models import densenet121\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "G7hT3K1LZLY_"
   },
   "source": [
    "# LOADING DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 610,
     "status": "ok",
     "timestamp": 1619026909098,
     "user": {
      "displayName": "aniket poojari",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Ggq_cw5GlJ_HceHGjFtLxCCLPqiYvg5ffKS76adUw=s64",
      "userId": "09624879631889696305"
     },
     "user_tz": -330
    },
    "id": "lDB7KMj61A86",
    "outputId": "ac2298eb-14a7-45ec-95c1-08e507ff36a1"
   },
   "outputs": [],
   "source": [
    "# defining the pre-processing steps\n",
    "normalize = transforms.Normalize([0.485, 0.456, 0.406], std = [0.229, 0.224, 0.225])\n",
    "resize = transforms.Resize((150, 150), interpolation = Image.NEAREST)\n",
    "preprocessing = transforms.Compose([resize, transforms.ToTensor(), normalize])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "executionInfo": {
     "elapsed": 858,
     "status": "ok",
     "timestamp": 1619026910770,
     "user": {
      "displayName": "aniket poojari",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Ggq_cw5GlJ_HceHGjFtLxCCLPqiYvg5ffKS76adUw=s64",
      "userId": "09624879631889696305"
     },
     "user_tz": -330
    },
    "id": "AAIY_6Er1V_N"
   },
   "outputs": [],
   "source": [
    "# defining the class to load dataset \n",
    "class EmergencyDataset(Dataset):\n",
    "    def __init__(self, csv_path, img_dir, transform):\n",
    "        df = pd.read_csv(csv_path)\n",
    "        self.img_dir = img_dir\n",
    "        self.csv_path = csv_path\n",
    "        self.img_name = df.image_name.values\n",
    "        self.y = df['label'].values\n",
    "        self.transform = transform\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        img = Image.open(self.img_dir + self.img_name[index])        \n",
    "        if self.transform is not None:\n",
    "            img = self.transform(img)\n",
    "        label = self.y[index]\n",
    "        return img, label\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.y.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "executionInfo": {
     "elapsed": 786,
     "status": "ok",
     "timestamp": 1619026911114,
     "user": {
      "displayName": "aniket poojari",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Ggq_cw5GlJ_HceHGjFtLxCCLPqiYvg5ffKS76adUw=s64",
      "userId": "09624879631889696305"
     },
     "user_tz": -330
    },
    "id": "H9Tcaw3o1bsD"
   },
   "outputs": [],
   "source": [
    "train_dataset = EmergencyDataset(csv_path = 'train.csv',\n",
    "                                 img_dir = 'images/',\n",
    "                                 transform = preprocessing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "executionInfo": {
     "elapsed": 1216,
     "status": "ok",
     "timestamp": 1619026912157,
     "user": {
      "displayName": "aniket poojari",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Ggq_cw5GlJ_HceHGjFtLxCCLPqiYvg5ffKS76adUw=s64",
      "userId": "09624879631889696305"
     },
     "user_tz": -330
    },
    "id": "JKHl29bW1bpK"
   },
   "outputs": [],
   "source": [
    "train_loader = DataLoader(dataset = train_dataset,\n",
    "                          batch_size = 32,\n",
    "                          shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "executionInfo": {
     "elapsed": 7524,
     "status": "ok",
     "timestamp": 1619026920810,
     "user": {
      "displayName": "aniket poojari",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Ggq_cw5GlJ_HceHGjFtLxCCLPqiYvg5ffKS76adUw=s64",
      "userId": "09624879631889696305"
     },
     "user_tz": -330
    },
    "id": "iM_njWoZ1bmX"
   },
   "outputs": [],
   "source": [
    "# getting the first batch\n",
    "for batch_idx, (batch_X, batch_y) in enumerate(train_loader):\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 903,
     "status": "ok",
     "timestamp": 1619026926753,
     "user": {
      "displayName": "aniket poojari",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Ggq_cw5GlJ_HceHGjFtLxCCLPqiYvg5ffKS76adUw=s64",
      "userId": "09624879631889696305"
     },
     "user_tz": -330
    },
    "id": "SV_Ga6ry1bgo",
    "outputId": "3572e139-582c-4d45-d8d0-772a8027dc5d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([32, 3, 150, 150]), torch.Size([32]))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# shape of the image and label\n",
    "batch_X.shape, batch_y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "I_2-Tk9Ll6mW"
   },
   "source": [
    "# PRETRAINED MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "executionInfo": {
     "elapsed": 818,
     "status": "ok",
     "timestamp": 1619026928676,
     "user": {
      "displayName": "aniket poojari",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Ggq_cw5GlJ_HceHGjFtLxCCLPqiYvg5ffKS76adUw=s64",
      "userId": "09624879631889696305"
     },
     "user_tz": -330
    },
    "id": "0DHCZLe_Gw7V"
   },
   "outputs": [],
   "source": [
    "# define model architecture along with pretrained weights of densenet121\n",
    "densenet_model = densenet121(pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 865,
     "status": "ok",
     "timestamp": 1619026929810,
     "user": {
      "displayName": "aniket poojari",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Ggq_cw5GlJ_HceHGjFtLxCCLPqiYvg5ffKS76adUw=s64",
      "userId": "09624879631889696305"
     },
     "user_tz": -330
    },
    "id": "7MfQXZG70zRX",
    "outputId": "d1febba8-4936-4cc4-8497-ad8666a20f04"
   },
   "outputs": [],
   "source": [
    "# print architecture of densenet121\n",
    "densenet_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "executionInfo": {
     "elapsed": 676,
     "status": "ok",
     "timestamp": 1619026931115,
     "user": {
      "displayName": "aniket poojari",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Ggq_cw5GlJ_HceHGjFtLxCCLPqiYvg5ffKS76adUw=s64",
      "userId": "09624879631889696305"
     },
     "user_tz": -330
    },
    "id": "UYwashr-Dcjq"
   },
   "outputs": [],
   "source": [
    "# freeze all parameters\n",
    "for param in densenet_model.parameters():\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1352,
     "status": "ok",
     "timestamp": 1619026933128,
     "user": {
      "displayName": "aniket poojari",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Ggq_cw5GlJ_HceHGjFtLxCCLPqiYvg5ffKS76adUw=s64",
      "userId": "09624879631889696305"
     },
     "user_tz": -330
    },
    "id": "a-yn5Pf50zYc",
    "outputId": "a1b14122-1e31-4fe1-ea77-ee0701523898"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 1024, 4, 4])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#understanding the output of densenet121 features block\n",
    "input = batch_X[:2]\n",
    "output= densenet_model.features(input)\n",
    "output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "executionInfo": {
     "elapsed": 1129,
     "status": "ok",
     "timestamp": 1619026934108,
     "user": {
      "displayName": "aniket poojari",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Ggq_cw5GlJ_HceHGjFtLxCCLPqiYvg5ffKS76adUw=s64",
      "userId": "09624879631889696305"
     },
     "user_tz": -330
    },
    "id": "S5RMzICoFtmX"
   },
   "outputs": [],
   "source": [
    "# transferring the model to GPU\n",
    "if torch.cuda.is_available():\n",
    "    densenet_model = densenet_model.cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qcSvbyj6m9fm"
   },
   "source": [
    "# EXTRACT FEATURES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 370
    },
    "executionInfo": {
     "elapsed": 163389,
     "status": "error",
     "timestamp": 1619027101909,
     "user": {
      "displayName": "aniket poojari",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Ggq_cw5GlJ_HceHGjFtLxCCLPqiYvg5ffKS76adUw=s64",
      "userId": "09624879631889696305"
     },
     "user_tz": -330
    },
    "id": "kwxIXYvj0zc5",
    "outputId": "f5071463-24aa-4277-f3ed-b3fdd8840bf5"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "533it [11:43,  1.32s/it]\n"
     ]
    }
   ],
   "source": [
    "# extract features using pretrained model \n",
    "\n",
    "#create an empty array to store features\n",
    "features = []\n",
    "target = []\n",
    "\n",
    "# set model to eval\n",
    "densenet_model.eval()\n",
    "\n",
    "#deactivates autograd\n",
    "with torch.no_grad():\n",
    "\n",
    "  # getting the data in batches using defined data loader\n",
    "  for batch_idx, (batch_X, batch_y) in tqdm(enumerate(train_loader)):\n",
    "    if torch.cuda.is_available():\n",
    "        batch_X = batch_X.cuda()\n",
    "    \n",
    "    # extract features\n",
    "    batch_features=densenet_model.features(batch_X)\n",
    "    \n",
    "    # Waits for everything to finish running\n",
    "    torch.cuda.synchronize()\n",
    "\n",
    "    #converting to numpy\n",
    "    batch_features = batch_features.data.cpu().numpy()\n",
    "\n",
    "    # append in list\n",
    "    features.append(batch_features)\n",
    "    target.append(batch_y)\n",
    "    \n",
    "#save to the array\n",
    "features = np.concatenate(features, axis=0)\n",
    "target = np.concatenate(target, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "1znFtBtmbAo6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17034, 1024, 4, 4)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 583,
     "status": "ok",
     "timestamp": 1618756240983,
     "user": {
      "displayName": "aniket poojari",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Ggq_cw5GlJ_HceHGjFtLxCCLPqiYvg5ffKS76adUw=s64",
      "userId": "09624879631889696305"
     },
     "user_tz": -330
    },
    "id": "th_D67lq8t__",
    "outputId": "389f4ba2-3903-4113-f2d2-b1693018675e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((17034, 16384), (17034,))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# flattening the features\n",
    "features = features.reshape(len(features),-1) \n",
    "features.shape, target.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OQPponjrsnAD"
   },
   "source": [
    "# TRAIN / VAL SPLIT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "JbpZNLjk8uL5"
   },
   "outputs": [],
   "source": [
    "X_train, X_valid, y_train, y_valid = train_test_split(features, target, test_size = 0.2, stratify = target, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 930,
     "status": "ok",
     "timestamp": 1618756296138,
     "user": {
      "displayName": "aniket poojari",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Ggq_cw5GlJ_HceHGjFtLxCCLPqiYvg5ffKS76adUw=s64",
      "userId": "09624879631889696305"
     },
     "user_tz": -330
    },
    "id": "606c6Q6P_ds_",
    "outputId": "e5c09a4d-2f9b-43b9-8a47-c46d0ad169e4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(((13627, 16384), (13627,)), ((3407, 16384), (3407,)))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(X_train.shape, y_train.shape), (X_valid.shape, y_valid.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "keQOc4wu_XVB"
   },
   "outputs": [],
   "source": [
    "# converting training and validation set to PyTorch tensor\n",
    "X_train = torch.FloatTensor(X_train)\n",
    "y_train = torch.FloatTensor(y_train)\n",
    "\n",
    "X_valid = torch.FloatTensor(X_valid)\n",
    "y_valid = torch.FloatTensor(y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "eknPMPMHVznL"
   },
   "outputs": [],
   "source": [
    "y_train = y_train.long()\n",
    "y_valid = y_valid.long()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a4TC5uI-OeAy"
   },
   "source": [
    "# MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "id": "8u5a-uWn3qF9"
   },
   "outputs": [],
   "source": [
    "model = Sequential(Linear(1024 * 4 * 4, 64),\n",
    "                   ReLU(),\n",
    "                   Linear(64, 32),\n",
    "                   ReLU(),\n",
    "                   Linear(32, 6),\n",
    "                   Softmax()\n",
    "                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 904,
     "status": "ok",
     "timestamp": 1618756377204,
     "user": {
      "displayName": "aniket poojari",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Ggq_cw5GlJ_HceHGjFtLxCCLPqiYvg5ffKS76adUw=s64",
      "userId": "09624879631889696305"
     },
     "user_tz": -330
    },
    "id": "65JkwsR9c-Fj",
    "outputId": "3e89b20e-2b08-4606-e7b8-15075be80ae7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Linear(in_features=16384, out_features=64, bias=True)\n",
       "  (1): ReLU()\n",
       "  (2): Linear(in_features=64, out_features=32, bias=True)\n",
       "  (3): ReLU()\n",
       "  (4): Linear(in_features=32, out_features=6, bias=True)\n",
       "  (5): Softmax(dim=None)\n",
       ")"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# summary of the model\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 915,
     "status": "ok",
     "timestamp": 1618756383159,
     "user": {
      "displayName": "aniket poojari",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Ggq_cw5GlJ_HceHGjFtLxCCLPqiYvg5ffKS76adUw=s64",
      "userId": "09624879631889696305"
     },
     "user_tz": -330
    },
    "id": "sZL984ZX6CLU",
    "outputId": "fdb84dca-21a9-4f5d-ccc6-ea8816e3e454"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.1575, 0.1614, 0.1883, 0.1632, 0.1400, 0.1896],\n",
       "        [0.1755, 0.1371, 0.1964, 0.1536, 0.1419, 0.1954]],\n",
       "       grad_fn=<SoftmaxBackward>)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pass an input to the model to understand the output\n",
    "model(X_train[0:2].view(2,1024*4*4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "id": "WVvYz82x98Br"
   },
   "outputs": [],
   "source": [
    "# define optimizer and loss function\n",
    "optimizer = torch.optim.Adam(model.parameters())\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# checking if GPU is available\n",
    "if torch.cuda.is_available():\n",
    "    model = model.cuda()\n",
    "    criterion = criterion.cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UQopxcD7RkrF"
   },
   "source": [
    "# TRAIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "id": "KGdT-qeTT6Hx"
   },
   "outputs": [],
   "source": [
    "def multiclass_accuracy(preds, y):\n",
    "    _, preds = torch.max(preds, 1)\n",
    "    correct_pred = (preds == y).float()\n",
    "    acc = correct_pred.sum() / len(correct_pred)\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "id": "kiSKF3G2DZM9"
   },
   "outputs": [],
   "source": [
    "# define training function\n",
    "def train(X,y,batch_size):\n",
    "\n",
    "  # activate training phase\n",
    "  model.train()\n",
    "  \n",
    "  # initialization\n",
    "  epoch_loss, epoch_acc= 0, 0\n",
    "  no_of_batches = 0\n",
    "\n",
    "  # randomly create indices\n",
    "  indices= torch.randperm(len(X))\n",
    "  \n",
    "  # loading in batches\n",
    "  for i in range(0,len(indices),batch_size):\n",
    "    \n",
    "    #indices for a batch\n",
    "    ind = indices[i:i+batch_size]\n",
    "  \n",
    "    # batch  \n",
    "    batch_x=X[ind]\n",
    "    batch_y=y[ind]\n",
    "    \n",
    "    # push to cuda\n",
    "    if torch.cuda.is_available():\n",
    "        batch_x, batch_y = batch_x.cuda(), batch_y.cuda()\n",
    "\n",
    "    # clear gradients\n",
    "    optimizer.zero_grad()\n",
    "          \n",
    "    # forward pass\n",
    "    outputs = model(batch_x)\n",
    "\n",
    "    # calculate loss and accuracy\n",
    "    loss = criterion(outputs, batch_y)\n",
    "    acc = multiclass_accuracy(outputs, batch_y)  \n",
    "    \n",
    "    # Backward pass\n",
    "    loss.backward()\n",
    "    \n",
    "    # Update weights\n",
    "    optimizer.step()\n",
    "\n",
    "    # Keep track of the loss and accuracy of a epoch\n",
    "    epoch_loss = epoch_loss + loss.item()\n",
    "    epoch_acc  = epoch_acc  + acc.item()\n",
    "\n",
    "    # No. of batches\n",
    "    no_of_batches = no_of_batches+1\n",
    "\n",
    "  return epoch_loss/no_of_batches, epoch_acc/no_of_batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "id": "_9uqS64DQ47l"
   },
   "outputs": [],
   "source": [
    "# define evaluation function\n",
    "def evaluate(X,y,batch_size):\n",
    "\n",
    "  # deactivate training phase\n",
    "  model.eval()\n",
    "\n",
    "  # initialization\n",
    "  epoch_loss, epoch_acc= 0, 0\n",
    "  no_of_batches = 0\n",
    "\n",
    "  # randomly create indices\n",
    "  indices= torch.randperm(len(X))\n",
    "\n",
    "  # deactivates autograd\n",
    "  with torch.no_grad():\n",
    "    \n",
    "    # loading in batches\n",
    "    for i in range(0,len(indices),batch_size):\n",
    "      \n",
    "      # indices for a batch\n",
    "      ind = indices[i:i+batch_size]\n",
    "  \n",
    "      # batch  \n",
    "      batch_x= X[ind]\n",
    "      batch_y= y[ind]\n",
    "\n",
    "      # push to cuda\n",
    "      if torch.cuda.is_available():\n",
    "          batch_x, batch_y = batch_x.cuda(), batch_y.cuda()\n",
    "        \n",
    "      # Forward pass\n",
    "      outputs = model(batch_x)\n",
    "\n",
    "      # Calculate loss and accuracy\n",
    "      loss = criterion(outputs, batch_y)\n",
    "      acc = multiclass_accuracy(outputs, batch_y)   \n",
    "      \n",
    "      # keep track of loss and accuracy of an epoch\n",
    "      epoch_loss = epoch_loss + loss.item()\n",
    "      epoch_acc  = epoch_acc  + acc.item()\n",
    "\n",
    "      # no. of batches\n",
    "      no_of_batches = no_of_batches + 1\n",
    "\n",
    "    return epoch_loss/no_of_batches, epoch_acc/no_of_batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 13150,
     "status": "ok",
     "timestamp": 1618756849935,
     "user": {
      "displayName": "aniket poojari",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Ggq_cw5GlJ_HceHGjFtLxCCLPqiYvg5ffKS76adUw=s64",
      "userId": "09624879631889696305"
     },
     "user_tz": -330
    },
    "id": "lSZ02Z-5RXun",
    "outputId": "cd42cb7c-731d-4c1b-ccf7-5b96d211a3c8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch : 0 Training loss: 1.106 \tTrain Accuracy: 0.9374 \tValidation loss: 1.1346 \tValidation Accuracy: 0.9089\n",
      "\n",
      "-----------------------------------------------Saved best model-------------------------------------------------------------\n",
      "\n",
      "Epoch : 1 Training loss: 1.1127 \tTrain Accuracy: 0.9307 \tValidation loss: 1.1388 \tValidation Accuracy: 0.9042\n",
      "\n",
      "Epoch : 2 Training loss: 1.1103 \tTrain Accuracy: 0.9331 \tValidation loss: 1.1349 \tValidation Accuracy: 0.9082\n",
      "\n",
      "Epoch : 3 Training loss: 1.1056 \tTrain Accuracy: 0.9378 \tValidation loss: 1.1304 \tValidation Accuracy: 0.9135\n",
      "\n",
      "-----------------------------------------------Saved best model-------------------------------------------------------------\n",
      "\n",
      "Epoch : 4 Training loss: 1.1047 \tTrain Accuracy: 0.9386 \tValidation loss: 1.1332 \tValidation Accuracy: 0.9105\n",
      "\n",
      "Epoch : 5 Training loss: 1.1034 \tTrain Accuracy: 0.9402 \tValidation loss: 1.1416 \tValidation Accuracy: 0.9016\n",
      "\n",
      "Epoch : 6 Training loss: 1.1048 \tTrain Accuracy: 0.9387 \tValidation loss: 1.1403 \tValidation Accuracy: 0.9027\n",
      "\n",
      "Epoch : 7 Training loss: 1.1032 \tTrain Accuracy: 0.9403 \tValidation loss: 1.1407 \tValidation Accuracy: 0.9032\n",
      "\n",
      "Epoch : 8 Training loss: 1.1032 \tTrain Accuracy: 0.9403 \tValidation loss: 1.1471 \tValidation Accuracy: 0.8968\n",
      "\n",
      "Epoch : 9 Training loss: 1.1061 \tTrain Accuracy: 0.9373 \tValidation loss: 1.1379 \tValidation Accuracy: 0.9053\n",
      "\n",
      "Epoch : 10 Training loss: 1.1041 \tTrain Accuracy: 0.9393 \tValidation loss: 1.1317 \tValidation Accuracy: 0.9118\n",
      "\n",
      "Epoch : 11 Training loss: 1.1027 \tTrain Accuracy: 0.9407 \tValidation loss: 1.1352 \tValidation Accuracy: 0.908\n",
      "\n",
      "Epoch : 12 Training loss: 1.103 \tTrain Accuracy: 0.9405 \tValidation loss: 1.1344 \tValidation Accuracy: 0.9094\n",
      "\n",
      "Epoch : 13 Training loss: 1.1008 \tTrain Accuracy: 0.9427 \tValidation loss: 1.1354 \tValidation Accuracy: 0.9079\n",
      "\n",
      "Epoch : 14 Training loss: 1.1022 \tTrain Accuracy: 0.9414 \tValidation loss: 1.133 \tValidation Accuracy: 0.9106\n",
      "\n",
      "Epoch : 15 Training loss: 1.1122 \tTrain Accuracy: 0.9313 \tValidation loss: 1.1408 \tValidation Accuracy: 0.9024\n",
      "\n",
      "Epoch : 16 Training loss: 1.0989 \tTrain Accuracy: 0.9446 \tValidation loss: 1.1385 \tValidation Accuracy: 0.9048\n",
      "\n",
      "Epoch : 17 Training loss: 1.1084 \tTrain Accuracy: 0.9351 \tValidation loss: 1.14 \tValidation Accuracy: 0.9034\n",
      "\n",
      "Epoch : 18 Training loss: 1.0976 \tTrain Accuracy: 0.9458 \tValidation loss: 1.1338 \tValidation Accuracy: 0.91\n",
      "\n",
      "Epoch : 19 Training loss: 1.0989 \tTrain Accuracy: 0.9447 \tValidation loss: 1.1443 \tValidation Accuracy: 0.8992\n"
     ]
    }
   ],
   "source": [
    "N_EPOCHS = 20\n",
    "batch_size = 32\n",
    "\n",
    "# intialization\n",
    "best_valid_acc = 0\n",
    "\n",
    "for epoch in range(N_EPOCHS):\n",
    "     \n",
    "    # train the model\n",
    "    train_loss, train_acc  = train(X_train, y_train, batch_size)\n",
    "    \n",
    "    # evaluate the model\n",
    "    valid_loss, valid_acc = evaluate(X_valid, y_valid, batch_size)\n",
    "\n",
    "    print('\\nEpoch :',epoch,\n",
    "          'Training loss:',round(train_loss,4),\n",
    "          '\\tTrain Accuracy:',round(train_acc,4),\n",
    "          '\\tValidation loss:',round(valid_loss,4),\n",
    "          '\\tValidation Accuracy:',round(valid_acc,4))\n",
    "\n",
    "    # save the best model\n",
    "    if best_valid_acc <= valid_acc:\n",
    "        best_valid_acc = valid_acc\n",
    "        torch.save(model.state_dict(), 'saved_weights.pt') \n",
    "        print(\"\\n-----------------------------------------------Saved best model-------------------------------------------------------------\")   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IJV1kqDuT7vU"
   },
   "source": [
    "# VALIDATE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1209,
     "status": "ok",
     "timestamp": 1618756966858,
     "user": {
      "displayName": "aniket poojari",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Ggq_cw5GlJ_HceHGjFtLxCCLPqiYvg5ffKS76adUw=s64",
      "userId": "09624879631889696305"
     },
     "user_tz": -330
    },
    "id": "ULe8TAjKA-n3",
    "outputId": "90163819-647f-4a3f-89a0-b5e3c94eda55"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load weights of best model\n",
    "path='saved_weights.pt'\n",
    "model.load_state_dict(torch.load(path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1221,
     "status": "ok",
     "timestamp": 1618756974445,
     "user": {
      "displayName": "aniket poojari",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Ggq_cw5GlJ_HceHGjFtLxCCLPqiYvg5ffKS76adUw=s64",
      "userId": "09624879631889696305"
     },
     "user_tz": -330
    },
    "id": "gGAlQEFoBaVj",
    "outputId": "352efba6-3014-4053-dcf6-35a8be373567"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 91.35124616533797\n"
     ]
    }
   ],
   "source": [
    "# performance on validation set\n",
    "valid_loss, valid_accuracy = evaluate(X_valid,y_valid,batch_size)\n",
    "\n",
    "print(\"Validation Accuracy:\",(valid_accuracy)*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YNHOZa_1b1g7"
   },
   "source": [
    "# TEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {
    "id": "p1TYneOkcIDN"
   },
   "outputs": [],
   "source": [
    "# defining the class to load dataset \n",
    "class TestEmergencyDataset(Dataset):\n",
    "    def __init__(self, csv_path, img_dir, transform):\n",
    "        df = pd.read_csv(csv_path)\n",
    "        self.img_dir = img_dir\n",
    "        self.csv_path = csv_path\n",
    "        self.img_name = df.image_name.values\n",
    "        self.len = df.shape[0]\n",
    "        self.transform = transform\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        img = Image.open(self.img_dir + self.img_name[index])\n",
    "        # converting any 2D image to 3D\n",
    "        if img.mode == \"L\":\n",
    "            img = np.array(img)\n",
    "            img1 = np.array([img,img,img])\n",
    "            img1 = img1.reshape(img1.shape[1], img1.shape[2], img1.shape[0])\n",
    "            img = Image.fromarray(img1)\n",
    "        if self.transform is not None:\n",
    "            img = self.transform(img)\n",
    "        return img\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {
    "id": "ItKy5vKsb_Qw"
   },
   "outputs": [],
   "source": [
    "test_dataset = TestEmergencyDataset(csv_path = 'test.csv',\n",
    "                                 img_dir = 'images/',\n",
    "                                 transform = preprocessing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {
    "id": "-ObaRtXHb_E0"
   },
   "outputs": [],
   "source": [
    "test_loader = DataLoader(dataset = test_dataset,\n",
    "                     batch_size = 32,\n",
    "                     shuffle = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 438
    },
    "executionInfo": {
     "elapsed": 14559,
     "status": "error",
     "timestamp": 1618758774175,
     "user": {
      "displayName": "aniket poojari",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Ggq_cw5GlJ_HceHGjFtLxCCLPqiYvg5ffKS76adUw=s64",
      "userId": "09624879631889696305"
     },
     "user_tz": -330
    },
    "id": "lFhnGz_Bb0vI",
    "outputId": "4c4e2990-c8d9-4fd7-aa50-b8e4abe473dc"
   },
   "outputs": [],
   "source": [
    "# getting the first batch\n",
    "for batch_idx, (batch_X) in enumerate(test_loader):\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 900,
     "status": "ok",
     "timestamp": 1618757670800,
     "user": {
      "displayName": "aniket poojari",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Ggq_cw5GlJ_HceHGjFtLxCCLPqiYvg5ffKS76adUw=s64",
      "userId": "09624879631889696305"
     },
     "user_tz": -330
    },
    "id": "nH7n0N-0dU3f",
    "outputId": "566502b9-9c65-4fbc-e5ec-6de0d8cde56b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 3, 150, 150])"
      ]
     },
     "execution_count": 234,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# shape of the image\n",
    "batch_X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {
    "id": "W1b1Udu2d0kX"
   },
   "outputs": [],
   "source": [
    "# define model architecture along with pretrained weights of densenet121\n",
    "densenet_model = densenet121(pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 907,
     "status": "ok",
     "timestamp": 1618757679036,
     "user": {
      "displayName": "aniket poojari",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Ggq_cw5GlJ_HceHGjFtLxCCLPqiYvg5ffKS76adUw=s64",
      "userId": "09624879631889696305"
     },
     "user_tz": -330
    },
    "id": "6Cu61ozhdU2G",
    "outputId": "d3ea9596-8b4c-4b17-9773-51e5d65ad876"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 1024, 4, 4])"
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#understanding the output of densenet121 features block\n",
    "input = batch_X[:2]\n",
    "output= densenet_model.features(input)\n",
    "output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {
    "id": "Qq56YhWvdUxk"
   },
   "outputs": [],
   "source": [
    "# transferring the model to GPU\n",
    "if torch.cuda.is_available():\n",
    "    densenet_model = densenet_model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {
    "id": "7n4o9RwddUv0"
   },
   "outputs": [],
   "source": [
    "# extract features using pretrained model \n",
    "\n",
    "#create an empty array to store features\n",
    "features = []\n",
    "\n",
    "# set model to eval\n",
    "densenet_model.eval()\n",
    "\n",
    "#deactivates autograd\n",
    "with torch.no_grad():\n",
    "\n",
    "  # getting the data in batches using defined data loader\n",
    "  for batch_idx, (batch_X) in enumerate(test_loader):\n",
    "    if torch.cuda.is_available():\n",
    "        batch_X = batch_X.cuda()\n",
    "    \n",
    "    # extract features\n",
    "    batch_features=densenet_model.features(batch_X)\n",
    "    \n",
    "    # Waits for everything to finish running\n",
    "    torch.cuda.synchronize()\n",
    "\n",
    "    #converting to numpy\n",
    "    batch_features = batch_features.data.cpu().numpy()\n",
    "\n",
    "    # append in list\n",
    "    features.append(batch_features)\n",
    "    \n",
    "#save to the array\n",
    "features = np.concatenate(features, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {
    "id": "QRHPmBxpdnHL"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7301, 16384)"
      ]
     },
     "execution_count": 239,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# flattening the features\n",
    "features = features.reshape(len(features),-1) \n",
    "features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {
    "id": "e_IcRK0JdnDA"
   },
   "outputs": [],
   "source": [
    "X_test = torch.FloatTensor(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {
    "id": "fbRY-SdTmj-2"
   },
   "outputs": [],
   "source": [
    "# define prediction function\n",
    "def predict(X, batch_size):\n",
    "  \n",
    "  # deactivate training phase\n",
    "  model.eval()\n",
    "\n",
    "  # initialization \n",
    "  predictions = []\n",
    "\n",
    "  # create indices\n",
    "  indices = torch.arange(len(X))\n",
    "\n",
    "  # deactivates autograd\n",
    "  with torch.no_grad():\n",
    "      \n",
    "      for i in range(0, len(X), batch_size):\n",
    "        \n",
    "        # indices for a batch\n",
    "        ind = indices[i:i+batch_size]\n",
    "\n",
    "        # batch\n",
    "        batch_x = X[ind]\n",
    "\n",
    "        # push to cuda\n",
    "        if torch.cuda.is_available():\n",
    "            batch_x = batch_x.cuda()\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(batch_x)\n",
    "\n",
    "        # converting the output to 1 Dimensional tensor\n",
    "        outputs = outputs.squeeze()\n",
    "\n",
    "        # convert to numpy array\n",
    "        prediction = outputs.data.cpu().numpy()\n",
    "        predictions.append(prediction)\n",
    "    \n",
    "  # convert to single numpy array\n",
    "  predictions = np.concatenate(predictions, axis=0)\n",
    "    \n",
    "  return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {
    "id": "GM7eVnijmzf8"
   },
   "outputs": [],
   "source": [
    "# Get probability of each class for each image\n",
    "pred = predict(X_test, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting the actual class\n",
    "pred = list(np.argmax(pred, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv(\"test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>14.jpg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  image_name\n",
       "0      3.jpg\n",
       "1      5.jpg\n",
       "2      6.jpg\n",
       "3     11.jpg\n",
       "4     14.jpg"
      ]
     },
     "execution_count": 245,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "test[\"label\"] = pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_name</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.jpg</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6.jpg</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.jpg</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>14.jpg</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  image_name  label\n",
       "0      3.jpg      5\n",
       "1      5.jpg      0\n",
       "2      6.jpg      4\n",
       "3     11.jpg      3\n",
       "4     14.jpg      5"
      ]
     },
     "execution_count": 247,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.to_csv('submit.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "Scene-Classification.ipynb",
   "provenance": [
    {
     "file_id": "19o4Q2v3CJSX2bhlAuiVDxJn4zdu4Bxe1",
     "timestamp": 1586256149157
    },
    {
     "file_id": "1wwDl_uV7rgto4G-ZmVwdqfEQkmE2p81h",
     "timestamp": 1586097992517
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
